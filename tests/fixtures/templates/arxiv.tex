\documentclass[11pt,letterpaper]{article}
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[table]{xcolor}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{array}
\usepackage{textcomp}
\usepackage{titlesec}
\titleformat{\section}{\bfseries\fontsize{14.0pt}{16.8pt}\selectfont}{\thesection}{1em}{}
\titlespacing*{\section}{0pt}{1em}{0.5em}
\titleformat{\subsection}{\bfseries\fontsize{12.0pt}{14.4pt}\selectfont}{\thesubsection}{1em}{}
\titlespacing*{\subsection}{0pt}{0.8em}{0.3em}
\usepackage{newcomputermodern}
\usepackage{setspace}
\setstretch{1.71}
\setlength{\parindent}{1.5em}
\providecommand{\textsubscript}[1]{$_{\text{#1}}$}
\begin{document}

\begin{center}
\textbf{ Your Paper Title: A Comprehensive Study of \\ Something Important in Your Field }\\ First Author\textsuperscript{1}*, Second Author\textsuperscript{2}, Third Author\textsuperscript{1,3} \\ \textsuperscript{1}Department of Computer Science, University Name, City, Country \\ \textsuperscript{2}Research Lab, Tech Company, City, Country \\ \textsuperscript{3}Institute for Advanced Study, City, Country \\\textit{ \textsuperscript{*}Corresponding author: first.author@university.edu }\\\textcolor[HTML]{666666}{ Preprint. Under review. }
\end{center}

\par\vspace{1.5em}

\textbf{Abstract} Write your abstract here. The abstract should provide a self-contained summary of your work, including the motivation, approach, key results, and conclusions. Most venues expect 150-300 words. Avoid citations in the abstract and ensure it can stand alone without the main text. This template follows the standard single-column format preferred by arXiv and many journals for initial submissions.

\par\vspace{1em}

\section{Introduction}

The introduction should establish the context for your work and clearly state the problem you're addressing. Begin with a broad overview of the field, then narrow down to the specific challenge or gap in knowledge that motivates your research.

In this paper, we present [brief description of your contribution]. Our approach differs from prior work in several key ways:

\begin{itemize}
  \item First key difference or innovation
  \item Second distinguishing feature
  \item Third novel aspect
\end{itemize}

The main contributions of this paper are:

\begin{enumerate}
  \item We propose [first contribution]
  \item We demonstrate [second contribution]
  \item We provide [third contribution, e.g., code, datasets, theoretical analysis]
\end{enumerate}

The rest of this paper is organized as follows. Section 2 reviews related work. Section 3 describes our methodology. Section 4 presents experimental results. Section 5 discusses implications and limitations. Section 6 concludes.

\section{Related Work}

Discuss prior research relevant to your work. Organize this section thematically or chronologically. Be sure to clearly distinguish your contributions from existing work.

\subsection{Prior Approaches}

Previous work on [topic] can be broadly categorized into [category 1] and [category 2].

Smith et al. [1] proposed an approach based on... However, this method is limited by...

Jones and colleagues [2] addressed this limitation by... While effective for [specific case], their approach does not generalize to...

\subsection{Theoretical Foundations}

The theoretical underpinnings of our work draw from [foundational work]. Key results include Theorem 1 from [3], which establishes...

\section{Methodology}

\subsection{Problem Formulation}

Let

\begin{equation}
x \in \mathbb{R}^n
\end{equation}

denote the input and

\begin{equation}
y \in {0, 1}
\end{equation}

the target label. We seek a function

\begin{equation}
f: \mathbb{R}^n \to {0, 1}
\end{equation}

that minimizes the expected loss:

\begin{equation}
\min_f \mathbb{E}_(x,y) [\mathcal{L}(f(x), y)]
\end{equation}

where

\begin{equation}
\mathcal{L}
\end{equation}

is a suitable loss function.

\subsection{Proposed Approach}

Our method consists of three main components:

\textbf{Component 1: Feature Extraction.} We first extract features using...

\textbf{Component 2: Model Architecture.} The extracted features are processed by...

\textbf{Component 3: Training Procedure.} We optimize the model using...

\begin{table}[h]
\centering
\begingroup
\setlength{\tabcolsep}{8pt}
\setlength{\arrayrulewidth}{0.5pt}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Hyperparameter} & \textbf{Value} & \textbf{Description} \\
\hline
Learning rate & $10^(-3)$ & Initial learning rate \\
\hline
Batch size & 64 & Training batch size \\
\hline
Epochs & 100 & Maximum training epochs \\
\hline
\end{tabular}
\endgroup
\caption{Hyperparameter settings for our experiments.}
\label{tab:hyperparams}
\end{table}

\subsection{Theoretical Analysis}

We now provide theoretical justification for our approach.

\textbf{Theorem 1.} \textit{Under assumptions A1-A3, the proposed algorithm converges to a stationary point at rate $O(1/\sqrt{T})$.}

\textbf{Proof.} The proof proceeds in three steps. First, we establish...

\begin{equation}
square
\end{equation}

\section{Experiments}

\subsection{Experimental Setup}

\textbf{Datasets.} We evaluate on three benchmark datasets: Dataset A (10K samples), Dataset B (50K samples), and Dataset C (100K samples).

\textbf{Baselines.} We compare against the following methods:

\begin{itemize}
  \item Baseline 1 [1]: Description
  \item Baseline 2 [4]: Description
  \item Baseline 3 [5]: Description
\end{itemize}

\textbf{Metrics.} We report accuracy, precision, recall, and F1-score.

\subsection{Main Results}

\begin{table}[h]
\centering
\begingroup
\setlength{\tabcolsep}{8pt}
\setlength{\arrayrulewidth}{0.5pt}
\begin{tabular}{|c|c|c|c|c|}
\hline
\textbf{Method} & \textbf{Accuracy} & \textbf{Precision} & \textbf{Recall} & \textbf{F1} \\
\hline
Baseline 1 & 72.3 & 70.1 & 74.5 & 72.2 \\
\hline
Baseline 2 & 75.8 & 73.2 & 78.1 & 75.6 \\
\hline
Baseline 3 & 77.2 & 75.8 & 78.3 & 77.0 \\
\hline
\textbf{Ours} & \textbf{83.5} & \textbf{81.2} & \textbf{85.1} & \textbf{83.1} \\
\hline
\end{tabular}
\endgroup
\caption{Performance comparison on Dataset A. Best results in bold.}
\label{tab:results}
\end{table}

As shown in Table 2, our method outperforms all baselines across all metrics.

\subsection{Ablation Study}

To understand the contribution of each component, we conduct ablation experiments...

\section{Discussion}

\subsection{Implications}

Our results suggest that [main finding]. This has implications for...

\subsection{Limitations}

While our approach demonstrates strong performance, several limitations remain:

\begin{itemize}
  \item Limitation 1: Description and potential mitigation
  \item Limitation 2: Description and future direction
  \item Limitation 3: Scope constraints
\end{itemize}

\subsection{Broader Impact}

We briefly discuss the potential societal impacts of this work...

\section{Conclusion}

We presented [summary of contribution]. Our experiments demonstrate [key finding]. Future work includes [directions].

\par\vspace{1em}

\textbf{Acknowledgments.} We thank [collaborators, funding agencies, compute providers]. This work was supported by [grant numbers].

\begin{thebibliography}{99}
\bibitem{ref1} Smith, A., Johnson, B., and Williams, C. "Title of the first paper." In \textit{Proceedings of Conference Name}, pages 1-10, 2023.
\bibitem{ref2} Jones, D. and Lee, E. "Title of the second paper." \textit{Journal Name}, 42(3):123-145, 2023.
\bibitem{ref3} Chen, F., et al. "Foundational paper title." In \textit{NeurIPS}, 2022.
\bibitem{ref4} Garcia, G. and Martinez, H. "Baseline method paper." In \textit{ICML}, pages 500-510, 2023.
\bibitem{ref5} Brown, I., et al. "Another baseline paper." \textit{JMLR}, 24:1-25, 2024.
\end{thebibliography}

\section{Appendix}

\subsection{Additional Experimental Details}

Detailed experimental settings and additional results...

\subsection{Proof of Theorem 1}

Full proof details...
\end{document}
